{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn                 import preprocessing       as pp\\nfrom sklearn                 import model_selection     as ms\\nfrom sklearn.preprocessing   import RobustScaler, MinMaxScaler, StandardScaler\\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\\nfrom sklearn.ensemble        import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\\nfrom xgboost                 import XGBClassifier\\nfrom sklearn.linear_model    import LogisticRegression, SGDClassifier\\nfrom sklearn.neighbors       import KNeighborsClassifier\\nfrom sklearn.tree            import DecisionTreeClassifier\\nfrom sklearn.ensemble        import RandomForestClassifier, BaggingClassifier\\nfrom sklearn.metrics         import accuracy_score, recall_score, precision_score, balanced_accuracy_score, f1_score, roc_curve, confusion_matrix\\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\\nfrom sklearn.naive_bayes     import GaussianNB\\nfrom lightgbm                import LGBMClassifier'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle               as pkl\n",
    "import pandas               as pd\n",
    "import numpy                as np\n",
    "import plotly_express       as px\n",
    "import matplotlib.pyplot    as plt\n",
    "\n",
    "from IPython.display         import HTML\n",
    "\n",
    "from sklearn                 import datasets            as ds\n",
    "from sklearn                 import tree                as tr\n",
    "from sklearn                 import metrics             as mt\n",
    "from sklearn                 import preprocessing       as pp\n",
    "from sklearn                 import model_selection     as ms\n",
    "from sklearn.preprocessing   import RobustScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.ensemble        import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from xgboost                 import XGBClassifier\n",
    "from sklearn.linear_model    import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors       import KNeighborsClassifier\n",
    "from sklearn.tree            import DecisionTreeClassifier\n",
    "from sklearn.ensemble        import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.metrics         import accuracy_score, recall_score, precision_score, balanced_accuracy_score, f1_score, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes     import GaussianNB\n",
    "from lightgbm                import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pickle.load(open('../dataset/processed/x_train.pkl', 'rb'))\n",
    "y_train = pickle.load(open('../dataset/processed/y_train.pkl', 'rb'))\n",
    "x_val = pickle.load(open('../dataset/processed/x_val.pkl', 'rb'))\n",
    "y_val = pickle.load(open('../dataset/processed/y_val.pkl', 'rb'))\n",
    "x_teste = pickle.load(open('../dataset/processed/x_test.pkl', 'rb'))\n",
    "y_teste = pickle.load(open('../dataset/processed/y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MachineLearning(dataset):\n",
    "    SEED = 42\n",
    "\n",
    "    lista_de_medidas = ['accuracy', 'recall', 'precision', 'balanced_accuracy', 'f1']\n",
    "    nome_das_medidas = ['acurácia', 'recall', 'precision', 'eficiência', 'f1-score']\n",
    "\n",
    "    lista_de_modelos = [XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3),\n",
    "                        SGDClassifier(loss='log_loss', random_state=SEED, n_jobs=-1), \n",
    "                        LGBMClassifier(random_state=SEED, n_jobs=-1, force_row_wise=True, ),\n",
    "                        GaussianNB(),\n",
    "                        LogisticRegression(max_iter=220, random_state=SEED),\n",
    "                        DecisionTreeClassifier(random_state=SEED),\n",
    "                        KNeighborsClassifier(n_neighbors=5,  weights='distance',n_jobs=-1),\n",
    "                        BaggingClassifier(),\n",
    "                        RandomForestClassifier(random_state=SEED)]\n",
    "\n",
    "    nome_dos_modelos = ['XGBClassifier', \n",
    "                        'SGDClassifier', \n",
    "                        'LGBMClassifier', \n",
    "                        'GaussianNB',\n",
    "                        'Regressão Logística',\n",
    "                        'DecisionTreeClassifier',\n",
    "                        'KNN',\n",
    "                        'BaggingClassifier',\n",
    "                        'RandomForestClassifier']\n",
    "\n",
    "    resultados0 = {}\n",
    "\n",
    "    for i in range(len(lista_de_modelos)):\n",
    "        print('Rodando modelo: ' + nome_dos_modelos[i])\n",
    "        accs_vc = cross_validate(lista_de_modelos[i], x_train, y_train, scoring = lista_de_medidas)\n",
    "        # cv = kf,\n",
    "\n",
    "\n",
    "        acc = accs_vc['test_accuracy'].mean()\n",
    "        sen = accs_vc['test_recall'].mean()\n",
    "        vpp = accs_vc['test_precision'].mean()\n",
    "        bac = accs_vc['test_balanced_accuracy'].mean()\n",
    "        f1s = accs_vc['test_f1'].mean()\n",
    "\n",
    "        resultados0[nome_dos_modelos[i]] = [acc, sen, vpp, f1s, bac]\n",
    "    \n",
    "    resultados = pd.DataFrame(resultados0, index = nome_das_medidas).T\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MachineLearning(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(model, x_train, y_train, x_teste):\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_teste)\n",
    "    \n",
    "    accuracy = accuracy_score(y_teste, y_pred)\n",
    "    recall = recall_score(y_teste, y_pred)\n",
    "    precision = precision_score(y_teste, y_pred)\n",
    "    balanced_accuracy = balanced_accuracy_score(y_teste, y_pred)\n",
    "    f1 = f1_score(y_teste, y_pred)\n",
    "\n",
    "    print(model)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "predic_xgb = train_and_predict(xgb, x_train, y_train, x_teste)\n",
    "\n",
    "predic_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SGDClassifier\n",
    "SEED = 42\n",
    "lgbm = LGBMClassifier(random_state=SEED, n_jobs=-1, force_row_wise=True)\n",
    "predic_lgbm = train_and_predict(lgbm, x_train, y_train, x_teste)\n",
    "\n",
    "\n",
    "predic_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SGDClassifier\n",
    "sgd = SGDClassifier(loss='log_loss', random_state=SEED, n_jobs=-1)\n",
    "predic_sgd = train_and_predict(sgd, x_train, y_train, x_teste)\n",
    "\n",
    "\n",
    "predic_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo SGDClassifier\n",
    "lr = LogisticRegression(max_iter=220, random_state=SEED)\n",
    "predic_lr = train_and_predict(lr, x_train, y_train, x_teste)\n",
    "\n",
    "predic_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Cria uma instância do GridSearchCV com o modelo XGBoost e os parâmetros definidos\n",
    "grid_search = GridSearchCV(XGBClassifier(), param_grid=param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprime os melhores parâmetros encontrados\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelo selecionado\n",
    "# XGBoosting já aplica o boosting então não precisa dessa etapa.\n",
    "\n",
    "# final_model = XGBClassifier( colsample_bytree= 0.8, learning_rate= 0.1, max_depth= 6, n_estimators= 100, subsample= 0.8 )\n",
    "final_model = XGBClassifier( colsample_bytree= 1.0, learning_rate= 0.1, max_depth= 3, n_estimators= 100, subsample= 0.8 )\n",
    "\n",
    "\n",
    "final_model.fit(x_train, y_train)\n",
    "y_pred = final_model.predict( x_teste )\n",
    "\n",
    "# Calculando as métricas de avaliação com base nas previsões da validação cruzada\n",
    "accuracy = accuracy_score(y_teste, y_pred)\n",
    "recall = recall_score(y_teste, y_pred)\n",
    "precision = precision_score(y_teste, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_teste, y_pred)\n",
    "f1 = f1_score(y_teste, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Balanced Accuracy:\", balanced_accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validação cruzada Leave One Out\n",
    "kf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "lista_de_medidas = ['precision', 'recall', 'f1']\n",
    "\n",
    "modelo_final_cv = XGBClassifier( colsample_bytree= 1.0, learning_rate= 0.1, max_depth= 3, n_estimators= 100, subsample= 0.8 )  \n",
    "\n",
    "kf_scores = cross_validate(modelo_final_cv, x_final, y_final, cv=kf, scoring=lista_de_medidas, n_jobs=-1)\n",
    "\n",
    "for medida in lista_de_medidas:\n",
    "    print(f\"Average {medida}: {kf_scores['test_' + medida].mean():.4f} (+/- {kf_scores['test_' + medida].std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.45\n",
    "\n",
    "modelo_final_cv = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=3)\n",
    "\n",
    "# Fit the model\n",
    "modelo_final_cv.fit(x_final, y_final)\n",
    "\n",
    "# Predict the probabilities\n",
    "modelo_final_cv_probs = modelo_final_cv.predict_proba(x_teste)\n",
    "\n",
    "# Keep probabilities for the positive outcome only\n",
    "probs = modelo_final_cv_probs[:, 1]\n",
    "\n",
    "# Apply the threshold\n",
    "y_pred = np.where(probs > threshold, 1, 0)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_teste, y_pred)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Juntando os Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino (80%) -> Treino(60%) + Validação(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino (80%) -> Treino(60%) + Validação(20%)\n",
    "train_80 = np.concatenate( (x_train, x_val) )\n",
    "val_80 = np.concatenate( (y_train, y_val) )\n",
    "\n",
    "#Treino Last -> Modelo + Melhor Parêmetro + Treino (80%)\n",
    "model_last = tr.DecisionTreeClassifier(max_depth=9)\n",
    "model_last.fit(train_80, val_80 )\n",
    "\n",
    "yhat_test = model_last.predict(x_teste)\n",
    "acc_test = mt.accuracy_score(y_teste, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treino ( Treino(60%) + Validação(20%) ) + Teste(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino ( Treino(60%) + Validação(20%) ) + Teste(20%)\n",
    "train_100 = np.concatenate( (train_80, x_teste) )\n",
    "val_100 = np.concatenate( (val_80, y_teste) )\n",
    "\n",
    "# Modelo em Produção\n",
    "model_last = tr.DecisionTreeClassifier(max_depth=9)\n",
    "model_last.fit( train_100, val_100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Exportar para o Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.to_csv('../dataset/production/data_set_kaggle.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "892e5ff5783333d733f0bd2e0068297de9409e96214f7e68af4469f351f76fae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
